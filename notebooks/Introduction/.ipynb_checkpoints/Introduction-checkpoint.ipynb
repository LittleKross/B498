{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "* The course is a mixture of programming and theory (mathematics) to learn from data\n",
    "    - Programming something is often the best way to understand it\n",
    "        - Python 3.x with libraries\n",
    "        - Coding algorithms, mathematical functions, etc\n",
    "        - Using algorithms and functions contained in libraries\n",
    "    - Math\n",
    "        - Basic Calculus (assume you know)\n",
    "            - Optimization\n",
    "        - Statistics and Probability\n",
    "        - Linear Algebra\n",
    "\n",
    "### Statistical/Machine Learning: Understanding Data\n",
    "\n",
    "* Three broad types\n",
    "    - Supervised: labeled training data\n",
    "    - Unsupervised: don't know truth\n",
    "    - Reinforcement Learning: reward for actions\n",
    "* Supervised\n",
    "    - Regression: Quantitative dependent variable\n",
    "    - Classification: Categorical dependent variable     \n",
    "* Unsupervised\n",
    "    - Clustering\n",
    "    - Dimension reduction\n",
    "\n",
    "#### Cognitive Science and Artificial Intelligence  is driven by Data\n",
    "\n",
    "* Improved data collection\n",
    "    - More sensors generate lots of data\n",
    "* Improved data processing\n",
    "    - Faster computers\n",
    "* Improved data storage\n",
    "    - Cheaper\n",
    "    \n",
    "#### What is difference between the terms statistical and machine learning\n",
    "\n",
    "* Often no difference, but\n",
    "    - Statistical learning tends to be more concerned with understanding relationships between data variables\n",
    "    - Machine learning tends to be more concerned with predicting new data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "### Real world and Model Data \n",
    "\n",
    "![Figure 1.](DataGen1.png)\n",
    "\n",
    "$$\\text{Figure 1. Relationship of Real-world and Model Data}$$\n",
    "\n",
    "* Generative model of unknown real-world process(causal) produces observations(data)\n",
    "    - Heights of college students in the US\n",
    "    \n",
    "* Statistical models make assumptions about distribution of the data\n",
    "    - Heights have a Normal Distribution (parameters are mean and standard deviation\n",
    "\n",
    "* Inference/Prediction using the model of the data to determine/explain data generating parameters\n",
    "    - Sample data: Heights of students in this class\n",
    "    - Determine mean and standard deviation\n",
    "    \n",
    "\n",
    "#### Probability and Statistics are required to manage and quantify uncertainty\n",
    "\n",
    "* Uncertainty \n",
    "    - Can be many different explanations/parameters\n",
    "    - Observed data is just a sample of the population of interest\n",
    "    - Incomplete information\n",
    "    - Measurement error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programming Tasks for Data Analysis and Interpretation\n",
    "\n",
    "![Figure 2.](DataFlow1.png)\n",
    "\n",
    "$$\\text{Figure 2. Data Analysis/Interpretation Tasks}$$\n",
    ".\n",
    " \n",
    "* Data preprocessing\n",
    "    - Import data from files, urls, databases in a variety of formats\n",
    "    - Clean and transform to structure appropriate for data processing\n",
    "    - Training/test split\n",
    "    - Scaling\n",
    "* Data exploration\n",
    "    - Data Visualization\n",
    "    - Describe central tendencies and variation in data\n",
    "* Data modeling\n",
    "    - Build a statistical model of data generating process\n",
    "    - Fit model to data\n",
    "    - Validate model\n",
    "    - Select best model\n",
    "* Predict new data\n",
    "* Produce results\n",
    "    - Validate\n",
    "    - Visualize\n",
    "    - Produce a report or paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics Covered in Course\n",
    "\n",
    "#### Background Material\n",
    "\n",
    "* Probability\n",
    "* Descriptive Statistics\n",
    "* Linear Algebra\n",
    "\n",
    "#### Data Preprocessing\n",
    "\n",
    "* Data collection and manipulation\n",
    "* Train/test split\n",
    "* Scaling\n",
    "* Encoding\n",
    "* Missing Values\n",
    "\n",
    "#### Data Visualization\n",
    "\n",
    "* Data Plots\n",
    "* Distribution Plots\n",
    "\n",
    "#### Learning Algorithms (subject to change)\n",
    "\n",
    "* K-nearest neighbor\n",
    "* Simple/Multivariate/Polynomial Linear Regression\n",
    "* Logistic Regression\n",
    "* Linear Discriminant Analysis\n",
    "* Support Vector Machine\n",
    "* Decision Trees\n",
    "* Random Forests\n",
    "* Bagging/Boosting\n",
    "* K-means/Hierarchical Clustering\n",
    "* Principal Component Analysis\n",
    "* Artificial Neural Networks\n",
    "* Convolutional Neural Networks\n",
    "* Recurrent Neural Networks\n",
    "\n",
    "#### Model Selection and Validation\n",
    "\n",
    "* Asses different models on speed, accuracy, and complexity\n",
    "* Bias-Variance Tradeoff\n",
    "* Cross Validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why so many Learning Algorithms?\n",
    "\n",
    "#### Isn't Deep Learning all we need?\n",
    "\n",
    "* No, way overhyped\n",
    "\n",
    "https://arxiv.org/pdf/1801.00631.pdf\n",
    "\n",
    "https://www.axios.com/artificial-intelligence-pioneer-says-we-need-to-start-over-1513305524-f619efbd-9db0-4947-a9b2-7a4c310a28fe.html\n",
    "\n",
    "#### \"No Free Lunch Theorem\" - Wolpert and Macready \n",
    "\n",
    "* Simplified: There is no one model that works best for every problem.\n",
    "\n",
    "#### Occam's Razor\n",
    "\n",
    "* Prefer simpler models over complex models\n",
    "\n",
    "\n",
    "#### \"All models are wrong, some are useful\"  George Box\n",
    "\n",
    "* Some are more useful than others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability and Statistics built into Programming Languages\n",
    "\n",
    "* Psuedo-random number generators \n",
    "    - Capability to reproduce random generation\n",
    "* Probability distributions\n",
    "* Sampling function\n",
    "* Descriptive and Inferential Statistics\n",
    "* Machine/Statistical Learning Algorithms\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Python Programming Language\n",
    "\n",
    "### Why Python (rather than R)?\n",
    "\n",
    "https://spectrum.ieee.org/at-work/innovation/the-2018-top-programming-languages\n",
    " \n",
    "* General purpose programming language\n",
    "    - Object-Oriented (OO)\n",
    "    - Interpreted/Interactive\n",
    "    - Functional\n",
    "* Easy to learn and use\n",
    "\n",
    "* Readable\n",
    "\n",
    "* Consistent\n",
    "    - e.g. use of OO by many packages\n",
    "    \n",
    "* Free, open source with large community\n",
    "\n",
    "* Widely used for Data Science\n",
    "    - http://www.kdnuggets.com/2017/08/new-poll-python-r-other.html\n",
    "    \n",
    "* Scientific and Numerical Packages\n",
    "    - Numpy\n",
    "    - Scipy\n",
    "* Machine Learning Packages\n",
    "    - Sklearn\n",
    "    - Keras\n",
    "* Data manipulation and analysis package\n",
    "    - Pandas\n",
    "* Visualization\n",
    "    - Matplotlib\n",
    "    - Seaborn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Monte Carlo calculation of e\n",
    "Shuffle a deck of 52 cards labeled 1 through n,\n",
    "and count how many times it happens that the ith card in the deck\n",
    "has label i. Then the probability of taht no card matches is approximately 1/e.\n",
    "''' \n",
    "import numpy as np\n",
    "np.random.seed(1234) # For reproducibility\n",
    "\n",
    "N = 10000\n",
    "accum_result = np.zeros(N)\n",
    "deck = np.arange(52)\n",
    "for j  in range(N):\n",
    "    np.random.shuffle(deck)\n",
    "    accum_result[j] = np.sum([deck[i] == i for i in range(52)])\n",
    "p_nomatch = np.sum(accum_result == 0) / N\n",
    "print(p_nomatch, 1/np.e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Probability Density Function (PDF) for a Normal Distribution\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.linspace(norm.ppf(0.01),norm.ppf(0.99), 100) # Range for x using quantiles\n",
    "plt.plot(x, norm.pdf(x),'r-', lw=5, alpha=0.6, label='norm pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from a Normal Distribution\n",
    "\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1234) \n",
    "\n",
    "rv = norm(2,.5)\n",
    "y = rv.rvs(100)\n",
    "print(type(rv))\n",
    "y[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.distplot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"iris.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data variables to dependent and independent variables\n",
    "X = df.loc[:,'sepal_length'].values\n",
    "print(X.shape,X.ndim)\n",
    "X = X.reshape(-1,1)\n",
    "y = df.loc[:,'petal_length'].values\n",
    "y = y.reshape(-1,1)\n",
    "print(X.shape,X.ndim,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "lm.fit(X,y)\n",
    "print(f'Intercept: {lm.intercept_ }, Slope: {lm.coef_[0]}')\n",
    "pred_x = 4.8\n",
    "ypred = lm.predict(pred_x)\n",
    "print(f'Predicted petal length for sepal length {pred_x} is {ypred[0][0]}')\n",
    "preds = lm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data and the best fitting (i.e.Regression) line\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X,y,'o')\n",
    "plt.plot(X,lm.intercept_ + lm.coef_[0]*X)\n",
    "plt.plot(X,preds,'o',color = 'r')\n",
    "plt.xlabel(\"Sepal Length\")\n",
    "plt.ylabel(\"Petal Length\")\n",
    "plt.title(\"Linear Regression\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
