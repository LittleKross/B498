{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "* The first and often the most time consuming step\n",
    "* Data must be in a form that the data learning or analysis algorithms expect\n",
    "\n",
    "![](data_cleaning.jpg)\n",
    "\n",
    "### Data Preprocessing Steps\n",
    "\n",
    "* Getting the dataset\n",
    "* Exploring the dataset\n",
    "* Missing Values\n",
    "* Categorical Values\n",
    "* Splitting the dataset\n",
    "* Scaling the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Ozone  Solar.R  Wind  Temp  Month  Day\n",
      "0     41.0    190.0   7.4    67      5    1\n",
      "1     36.0    118.0   8.0    72      5    2\n",
      "2     12.0    149.0  12.6    74      5    3\n",
      "3     18.0    313.0  11.5    62      5    4\n",
      "4      NaN      NaN  14.3    56      5    5\n",
      "..     ...      ...   ...   ...    ...  ...\n",
      "148   30.0    193.0   6.9    70      9   26\n",
      "149    NaN    145.0  13.2    77      9   27\n",
      "150   14.0    191.0  14.3    75      9   28\n",
      "151   18.0    131.0   8.0    76      9   29\n",
      "152   20.0    223.0  11.5    68      9   30\n",
      "\n",
      "[153 rows x 6 columns]\n",
      "0       7.4\n",
      "1       8.0\n",
      "2      12.6\n",
      "3      11.5\n",
      "4      14.3\n",
      "       ... \n",
      "148     6.9\n",
      "149    13.2\n",
      "150    14.3\n",
      "151     8.0\n",
      "152    11.5\n",
      "Name: Wind, Length: 153, dtype: float64\n",
      "0      41.0\n",
      "1      36.0\n",
      "2      12.0\n",
      "3      18.0\n",
      "4       NaN\n",
      "       ... \n",
      "148    30.0\n",
      "149     NaN\n",
      "150    14.0\n",
      "151    18.0\n",
      "152    20.0\n",
      "Name: Ozone, Length: 153, dtype: float64\n",
      "   Ozone  Solar.R  Wind  Temp  Month  Day\n",
      "0   41.0    190.0   7.4    67      5    1\n",
      "1   36.0    118.0   8.0    72      5    2\n",
      "2   12.0    149.0  12.6    74      5    3\n",
      "3   18.0    313.0  11.5    62      5    4\n",
      "4    NaN      NaN  14.3    56      5    5\n",
      "5   28.0      NaN  14.9    66      5    6\n",
      "6   23.0    299.0   8.6    65      5    7\n",
      "7   19.0     99.0  13.8    59      5    8\n",
      "8    8.0     19.0  20.1    61      5    9\n",
      "9    NaN    194.0   8.6    69      5   10\n"
     ]
    }
   ],
   "source": [
    "aq = pd.read_csv(\"airquality.csv\")\n",
    "aq.head()\n",
    "# if you want to see all data, uncomment the line below\n",
    "#pd.set_option('display.max_rows', None) \n",
    "print(aq)\n",
    "print(aq.iloc[:,2]) # column 0 is Ozone, column 2 is Wind\n",
    "print(aq.loc[:,'Ozone'])\n",
    "print(aq.iloc[0:10]) # rows 0 through 9, all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size\n",
       "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
       "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
       "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
       "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
       "4       24.59  3.61  Female     No  Sun  Dinner     4"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips = sns.load_dataset(\"tips\")\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "\n",
    "* Generally indicated by NaN in Python\n",
    "    - May be an extreme value like 9999\n",
    "* Delete Row\n",
    "    - Not a good idea unless have lots of repeated measures\n",
    "* Fill in with the column mean, median, or mode\n",
    "* Fill in with mean of neighboring items \n",
    "* When using a statistic fit imputer to training data.\n",
    "    - Transform both the training data and test data with the fit imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_bill    0\n",
       "tip           0\n",
       "sex           0\n",
       "smoker        0\n",
       "day           0\n",
       "time          0\n",
       "size          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ozone      37\n",
       "Solar.R     7\n",
       "Wind        0\n",
       "Temp        0\n",
       "Month       0\n",
       "Day         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aq.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aq.loc[:,'Wind'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(aq.iloc[:,3]).sum()  #check for missing values in Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of missing values in Ozone is 24.18\n"
     ]
    }
   ],
   "source": [
    "percent_missing = aq.loc[:,'Ozone'].isnull().sum() / aq.shape[0]\n",
    "print(f'% of missing values in Ozone is {round(percent_missing*100,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.5  2.   3. ]\n",
      " [ 4.   3.5  6. ]\n",
      " [10.   3.5  9. ]]\n"
     ]
    }
   ],
   "source": [
    "#impute NaN data with mean \n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp_mean = SimpleImputer(missing_values = np.nan, strategy='mean') # create the imputer, mean of the column is used\n",
    "imp_mean.fit([[np.nan, 2, 3], [5, np.nan, 6], [10, 5, 9]]) # fit it to the \n",
    "SimpleImputer()\n",
    "X = [[np.nan, 2, 3], [4, np.nan, 6], [10, np.nan, 9]]\n",
    "Y = imp_mean.transform(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 41.         190.           7.4         67.        ]\n",
      " [ 36.         118.           8.          72.        ]\n",
      " [ 12.         149.          12.6         74.        ]\n",
      " [ 18.         313.          11.5         62.        ]\n",
      " [  9.95751634  77.88235294  14.3         56.        ]\n",
      " [ 28.          77.88235294  14.9         66.        ]\n",
      " [ 23.         299.           8.6         65.        ]\n",
      " [ 19.          99.          13.8         59.        ]\n",
      " [  8.          19.          20.1         61.        ]\n",
      " [  9.95751634 194.           8.6         69.        ]\n",
      " [  7.          77.88235294   6.9         74.        ]\n",
      " [ 16.         256.           9.7         69.        ]\n",
      " [ 11.         290.           9.2         66.        ]\n",
      " [ 14.         274.          10.9         68.        ]\n",
      " [ 18.          65.          13.2         58.        ]\n",
      " [ 14.         334.          11.5         64.        ]\n",
      " [ 34.         307.          12.          66.        ]\n",
      " [  6.          78.          18.4         57.        ]\n",
      " [ 30.         322.          11.5         68.        ]\n",
      " [ 11.          44.           9.7         62.        ]\n",
      " [  1.           8.           9.7         59.        ]\n",
      " [ 11.         320.          16.6         73.        ]\n",
      " [  4.          25.           9.7         61.        ]\n",
      " [ 32.          92.          12.          61.        ]\n",
      " [  9.95751634  66.          16.6         57.        ]\n",
      " [  9.95751634 266.          14.9         58.        ]\n",
      " [  9.95751634  77.88235294   8.          57.        ]\n",
      " [ 23.          13.          12.          67.        ]\n",
      " [ 45.         252.          14.9         81.        ]\n",
      " [115.         223.           5.7         79.        ]\n",
      " [ 37.         279.           7.4         76.        ]\n",
      " [  9.95751634 286.           8.6         78.        ]\n",
      " [  9.95751634 287.           9.7         74.        ]\n",
      " [  9.95751634 242.          16.1         67.        ]\n",
      " [  9.95751634 186.           9.2         84.        ]\n",
      " [  9.95751634 220.           8.6         85.        ]\n",
      " [  9.95751634 264.          14.3         79.        ]\n",
      " [ 29.         127.           9.7         82.        ]\n",
      " [  9.95751634 273.           6.9         87.        ]\n",
      " [ 71.         291.          13.8         90.        ]\n",
      " [ 39.         323.          11.5         87.        ]\n",
      " [  9.95751634 259.          10.9         93.        ]\n",
      " [  9.95751634 250.           9.2         92.        ]\n",
      " [ 23.         148.           8.          82.        ]\n",
      " [  9.95751634 332.          13.8         80.        ]\n",
      " [  9.95751634 322.          11.5         79.        ]\n",
      " [ 21.         191.          14.9         77.        ]\n",
      " [ 37.         284.          20.7         72.        ]\n",
      " [ 20.          37.           9.2         65.        ]\n",
      " [ 12.         120.          11.5         73.        ]\n",
      " [ 13.         137.          10.3         76.        ]\n",
      " [  9.95751634 150.           6.3         77.        ]\n",
      " [  9.95751634  59.           1.7         76.        ]\n",
      " [  9.95751634  91.           4.6         76.        ]\n",
      " [  9.95751634 250.           6.3         76.        ]\n",
      " [  9.95751634 135.           8.          75.        ]\n",
      " [  9.95751634 127.           8.          78.        ]\n",
      " [  9.95751634  47.          10.3         73.        ]\n",
      " [  9.95751634  98.          11.5         80.        ]\n",
      " [  9.95751634  31.          14.9         77.        ]\n",
      " [  9.95751634 138.           8.          83.        ]\n",
      " [135.         269.           4.1         84.        ]\n",
      " [ 49.         248.           9.2         85.        ]\n",
      " [ 32.         236.           9.2         81.        ]\n",
      " [  9.95751634 101.          10.9         84.        ]\n",
      " [ 64.         175.           4.6         83.        ]\n",
      " [ 40.         314.          10.9         83.        ]\n",
      " [ 77.         276.           5.1         88.        ]\n",
      " [ 97.         267.           6.3         92.        ]\n",
      " [ 97.         272.           5.7         92.        ]\n",
      " [ 85.         175.           7.4         89.        ]\n",
      " [  9.95751634 139.           8.6         82.        ]\n",
      " [ 10.         264.          14.3         73.        ]\n",
      " [ 27.         175.          14.9         81.        ]\n",
      " [  9.95751634 291.          14.9         91.        ]\n",
      " [  7.          48.          14.3         80.        ]\n",
      " [ 48.         260.           6.9         81.        ]\n",
      " [ 35.         274.          10.3         82.        ]\n",
      " [ 61.         285.           6.3         84.        ]\n",
      " [ 79.         187.           5.1         87.        ]\n",
      " [ 63.         220.          11.5         85.        ]\n",
      " [ 16.           7.           6.9         74.        ]\n",
      " [  9.95751634 258.           9.7         81.        ]\n",
      " [  9.95751634 295.          11.5         82.        ]\n",
      " [ 80.         294.           8.6         86.        ]\n",
      " [108.         223.           8.          85.        ]\n",
      " [ 20.          81.           8.6         82.        ]\n",
      " [ 52.          82.          12.          86.        ]\n",
      " [ 82.         213.           7.4         88.        ]\n",
      " [ 50.         275.           7.4         86.        ]\n",
      " [ 64.         253.           7.4         83.        ]\n",
      " [ 59.         254.           9.2         81.        ]\n",
      " [ 39.          83.           6.9         81.        ]\n",
      " [  9.          24.          13.8         81.        ]\n",
      " [ 16.          77.           7.4         82.        ]\n",
      " [ 78.          77.88235294   6.9         86.        ]\n",
      " [ 35.          77.88235294   7.4         85.        ]\n",
      " [ 66.          77.88235294   4.6         87.        ]\n",
      " [122.         255.           4.          89.        ]\n",
      " [ 89.         229.          10.3         90.        ]\n",
      " [110.         207.           8.          90.        ]\n",
      " [  9.95751634 222.           8.6         92.        ]\n",
      " [  9.95751634 137.          11.5         86.        ]\n",
      " [ 44.         192.          11.5         86.        ]\n",
      " [ 28.         273.          11.5         82.        ]\n",
      " [ 65.         157.           9.7         80.        ]\n",
      " [  9.95751634  64.          11.5         79.        ]\n",
      " [ 22.          71.          10.3         77.        ]\n",
      " [ 59.          51.           6.3         79.        ]\n",
      " [ 23.         115.           7.4         76.        ]\n",
      " [ 31.         244.          10.9         78.        ]\n",
      " [ 44.         190.          10.3         78.        ]\n",
      " [ 21.         259.          15.5         77.        ]\n",
      " [  9.          36.          14.3         72.        ]\n",
      " [  9.95751634 255.          12.6         75.        ]\n",
      " [ 45.         212.           9.7         79.        ]\n",
      " [168.         238.           3.4         81.        ]\n",
      " [ 73.         215.           8.          86.        ]\n",
      " [  9.95751634 153.           5.7         88.        ]\n",
      " [ 76.         203.           9.7         97.        ]\n",
      " [118.         225.           2.3         94.        ]\n",
      " [ 84.         237.           6.3         96.        ]\n",
      " [ 85.         188.           6.3         94.        ]\n",
      " [ 96.         167.           6.9         91.        ]\n",
      " [ 78.         197.           5.1         92.        ]\n",
      " [ 73.         183.           2.8         93.        ]\n",
      " [ 91.         189.           4.6         93.        ]\n",
      " [ 47.          95.           7.4         87.        ]\n",
      " [ 32.          92.          15.5         84.        ]\n",
      " [ 20.         252.          10.9         80.        ]\n",
      " [ 23.         220.          10.3         78.        ]\n",
      " [ 21.         230.          10.9         75.        ]\n",
      " [ 24.         259.           9.7         73.        ]\n",
      " [ 44.         236.          14.9         81.        ]\n",
      " [ 21.         259.          15.5         76.        ]\n",
      " [ 28.         238.           6.3         77.        ]\n",
      " [  9.          24.          10.9         71.        ]\n",
      " [ 13.         112.          11.5         71.        ]\n",
      " [ 46.         237.           6.9         78.        ]\n",
      " [ 18.         224.          13.8         67.        ]\n",
      " [ 13.          27.          10.3         76.        ]\n",
      " [ 24.         238.          10.3         68.        ]\n",
      " [ 16.         201.           8.          82.        ]\n",
      " [ 13.         238.          12.6         64.        ]\n",
      " [ 23.          14.           9.2         71.        ]\n",
      " [ 36.         139.          10.3         81.        ]\n",
      " [  7.          49.          10.3         69.        ]\n",
      " [ 14.          20.          16.6         63.        ]\n",
      " [ 30.         193.           6.9         70.        ]\n",
      " [  9.95751634 145.          13.2         77.        ]\n",
      " [ 14.         191.          14.3         75.        ]\n",
      " [ 18.         131.           8.          76.        ]\n",
      " [ 20.         223.          11.5         68.        ]]\n",
      "% of missing values in Ozone is Ozone      0.0\n",
      "Solar.R    0.0\n",
      "Wind       0.0\n",
      "Temp       0.0\n",
      "Month      0.0\n",
      "Day        0.0\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 5.],\n",
       "       [3., 4., 3.],\n",
       "       [4., 6., 5.],\n",
       "       [8., 8., 7.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#following two blocks of code demonstrate how to use two different imputers \n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "X = aq.iloc[:,0:4].values # extract the first 4 columns \n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy='mean') #replace NaN with mean\n",
    "imputer = imputer.fit(X[:,2:]) # fit the imputer for first two features\n",
    "X[:,0:2] = imputer.transform(X[:,0:2]) # transform and store back\n",
    "print(X)\n",
    "\n",
    "# now look back if any missing values in Ozone column\n",
    "percent_missing = aq.iloc[:2].isnull().sum() / aq.shape[0]\n",
    "print(f'% of missing values in Ozone is {round(percent_missing*100,2)}') # output should be 0.0\n",
    "\n",
    "\n",
    "# This is an example of K-nearest neighbor (KNN) imputation \n",
    "# KNN is a classifire algorithm in Machine Learning (We will study this in a later Module)\n",
    "# The KNN algorithm assumes that similar things exist in close proximity. Thus, it imputes the \n",
    "# missing values based on N number of proximity values. Here N ois set at 3. \n",
    "from sklearn.impute import KNNImputer \n",
    "nan = np.nan\n",
    "X = [[1, 2, nan], [3, 4, 3], [nan, 6, 5], [8, 8, 7]]\n",
    "imputer = KNNImputer(n_neighbors=3, weights=\"uniform\")\n",
    "imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Data\n",
    " \n",
    "* Labeled data\n",
    "    - Labels can be strings (i.e. nominal variables) or numbers\n",
    "    - Gender, Species in the iris dataset, number of cylinders in a car\n",
    "    - Sometimes no ordering is implied\n",
    "        - Gender, iris$Species\n",
    "    - Sometimes there is a natural ordering\n",
    "        - Size (small,medium or large), number of cylinders in a car\n",
    "* Can be independent or dependent variable\n",
    "    - When its the independent variable it serves as a grouping variable (e.g. in a boxplot)\n",
    "        - Is there a difference in Sepal.Length by group?\n",
    "    - As a dependent variable in Classification problems we classify new observations into one of the grourps\n",
    "* Statistical(machine learning) models are based on mathematical equations that require integer values not strings\n",
    "    - Need to encode strings as integers (called Dummy Encoding)\n",
    "    - Will go into more detail when we cover multiple Linear Regression\n",
    "\n",
    "* We will use the LabelEncoder class to do dummy encoding \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width  species\n",
      "0           5.1          3.5           1.4          0.2        0\n",
      "1           4.9          3.0           1.4          0.2        0\n",
      "2           4.7          3.2           1.3          0.2        0\n",
      "3           4.6          3.1           1.5          0.2        0\n",
      "4           5.0          3.6           1.4          0.2        0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width  species\n",
       "145           6.7          3.0           5.2          2.3        2\n",
       "146           6.3          2.5           5.0          1.9        2\n",
       "147           6.5          3.0           5.2          2.0        2\n",
       "148           6.2          3.4           5.4          2.3        2\n",
       "149           5.9          3.0           5.1          1.8        2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = sns.load_dataset(\"iris\") #https://seaborn.pydata.org/generated/seaborn.load_dataset.html\n",
    "# load it from git, need internet\n",
    "from sklearn.preprocessing import LabelEncoder #https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "iris.iloc[:, 4] = label_encoder.fit_transform(iris.iloc[:, 4]) # dummy encoding species attribute\n",
    "print(iris.head())\n",
    "iris.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot encoding\n",
    "A representing categorical variables as binary vectors. It allows the representation of categorical data to be more expressive. \n",
    "Many machine learning algorithms cannot work with categorical data directly. The categories must be converted into numbers. This is required for both input and output variables that are categorical.\n",
    "Dummy encoding may work for problems where there is a natural ordinal relationship between the categories (attribute values) such as labels for weather; cold, sunny, rainy, cloudy, etc. But problems with no natural ordinal relationship between the categories such as 'cat' or 'dog' could cause problems in especially learning algorithms. \n",
    "Lets use the One-hot encoder in an example.\n",
    "\n",
    "Example:\n",
    "Imagine if you had 3 categories of foods: apples, chicken, and broccoli. Using label encoding, you would assign each of these a number to categorize them: apples = 1, chicken = 2, and broccoli = 3. But now, if your model internally needs to calculate the average across categories, it might do do 1+3 = 4/2 = 2. This means that according to your model, the average of apples and chicken together is broccoli.\n",
    "\n",
    "Obviously that line of thinking by your model is going to lead to it getting correlations completely wrong. \n",
    "\n",
    "Tables below show before and after one-hot encoding\n",
    "\n",
    "![](encodingtable.jpeg)\n",
    "\n",
    "Well, our categories were formerly rows, but now they’re columns. Our numerical variable, calories, has however stayed the same.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content of the data file\n",
      "\n",
      "  FoodName  CategoryNumber  Calories\n",
      "0    Apple               1        80\n",
      "1     Pear               2        72\n",
      "2  Chicken               3       220\n",
      "3   Carrot               4        45\n",
      "4     Beef               5       418\n",
      "\n",
      " data from first two columns\n",
      "\n",
      "[['Apple' 1]\n",
      " ['Pear' 2]\n",
      " ['Chicken' 3]\n",
      " ['Carrot' 4]\n",
      " ['Beef' 5]]\n",
      "\n",
      " first two columns are both numerical now, first column values 0-4, but second  column is not encoded. \n",
      "\n",
      "[[0 1]\n",
      " [4 2]\n",
      " [3 3]\n",
      " [2 4]\n",
      " [1 5]]\n",
      "\n",
      " both columns are encoded using one-hot encoding \n",
      "\n",
      "[[1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "onehotdata = pd.read_csv('foodcategories.csv')\n",
    "print('content of the data file\\n')\n",
    "print(onehotdata) #output data from file\n",
    "X = onehotdata.iloc[:, :-1].values # we care about the first two columns, but all rows\n",
    "print('\\n data from first two columns\\n')\n",
    "print(X)\n",
    "le = LabelEncoder()\n",
    "X[:, 0] = le.fit_transform(X[:, 0]) # converting first column's categorical data to numerical\n",
    "print('\\n first two columns are both numerical now, first column values 0-4, but second  column is not encoded. \\n')\n",
    "print(X)\n",
    "ohe = OneHotEncoder(categories= 'auto')\n",
    "X = ohe.fit_transform(X).toarray()\n",
    "\n",
    "print('\\n both columns are encoded using one-hot encoding \\n')\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  age   bp     sg al su       rbc        pc         pcc          ba  bgr  ...  \\\n",
      "0  48   80  1.020  1  0         ?    normal  notpresent  notpresent  121  ...   \n",
      "1   7   50  1.020  4  0         ?    normal  notpresent  notpresent    ?  ...   \n",
      "2  62   80  1.010  2  3    normal    normal  notpresent  notpresent  423  ...   \n",
      "3  48   70  1.005  4  0    normal  abnormal     present  notpresent  117  ...   \n",
      "4  51   80  1.010  2  0    normal    normal  notpresent  notpresent  106  ...   \n",
      "5  60   90  1.015  3  0         ?         ?  notpresent  notpresent   74  ...   \n",
      "6  68   70  1.010  0  0         ?    normal  notpresent  notpresent  100  ...   \n",
      "7  24    ?  1.015  2  4    normal  abnormal  notpresent  notpresent  410  ...   \n",
      "8  52  100  1.015  3  0    normal  abnormal     present  notpresent  138  ...   \n",
      "9  53   90  1.020  2  0  abnormal  abnormal     present  notpresent   70  ...   \n",
      "\n",
      "  pcv     wc   rc  htn   dm cad appet   pe  ane class  \n",
      "0  44   7800  5.2  yes  yes  no  good   no   no   ckd  \n",
      "1  38   6000    ?   no   no  no  good   no   no   ckd  \n",
      "2  31   7500    ?   no  yes  no  poor   no  yes   ckd  \n",
      "3  32   6700  3.9  yes   no  no  poor  yes  yes   ckd  \n",
      "4  35   7300  4.6   no   no  no  good   no   no   ckd  \n",
      "5  39   7800  4.4  yes  yes  no  good  yes   no   ckd  \n",
      "6  36      ?    ?   no   no  no  good   no   no   ckd  \n",
      "7  44   6900    5   no  yes  no  good  yes   no   ckd  \n",
      "8  33   9600  4.0  yes  yes  no  good   no  yes   ckd  \n",
      "9  29  12100  3.7  yes  yes  no  poor   no  yes   ckd  \n",
      "\n",
      "[10 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Data set is from https://archive.ics.uci.edu/ml/datasets/chronic_kidney_disease\n",
    "# It is given to you in the folder as a CSV file\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv('chronic_kidney_disease.csv', header=None, \n",
    " names=['age', 'bp', 'sg', 'al', 'su', 'rbc', 'pc', 'pcc', 'ba', 'bgr', 'bu', 'sc', 'sod', 'pot',\n",
    " 'hemo', 'pcv', 'wc', 'rc', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane', 'class'])\n",
    "# head of df\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice in the above output that there are missing values, thus we need to handle missing values before we deal with encoding of columns like 'rbc', 'pc', 'pcc', etc.\n",
    "Take care of the missing vallues first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age     bp     sg   al   su       rbc        pc         pcc          ba  \\\n",
      "0  48.0   80.0  1.020  1.0  0.0       NaN    normal  notpresent  notpresent   \n",
      "1   7.0   50.0  1.020  4.0  0.0       NaN    normal  notpresent  notpresent   \n",
      "2  62.0   80.0  1.010  2.0  3.0    normal    normal  notpresent  notpresent   \n",
      "3  48.0   70.0  1.005  4.0  0.0    normal  abnormal     present  notpresent   \n",
      "4  51.0   80.0  1.010  2.0  0.0    normal    normal  notpresent  notpresent   \n",
      "5  60.0   90.0  1.015  3.0  0.0       NaN       NaN  notpresent  notpresent   \n",
      "6  68.0   70.0  1.010  0.0  0.0       NaN    normal  notpresent  notpresent   \n",
      "7  24.0    NaN  1.015  2.0  4.0    normal  abnormal  notpresent  notpresent   \n",
      "8  52.0  100.0  1.015  3.0  0.0    normal  abnormal     present  notpresent   \n",
      "9  53.0   90.0  1.020  2.0  0.0  abnormal  abnormal     present  notpresent   \n",
      "\n",
      "     bgr  ...   pcv       wc   rc  htn   dm  cad  appet   pe  ane class  \n",
      "0  121.0  ...  44.0   7800.0  5.2  yes  yes   no   good   no   no     0  \n",
      "1    NaN  ...  38.0   6000.0  NaN   no   no   no   good   no   no     0  \n",
      "2  423.0  ...  31.0   7500.0  NaN   no  yes   no   poor   no  yes     0  \n",
      "3  117.0  ...  32.0   6700.0  3.9  yes   no   no   poor  yes  yes     0  \n",
      "4  106.0  ...  35.0   7300.0  4.6   no   no   no   good   no   no     0  \n",
      "5   74.0  ...  39.0   7800.0  4.4  yes  yes   no   good  yes   no     0  \n",
      "6  100.0  ...  36.0      NaN  NaN   no   no   no   good   no   no     0  \n",
      "7  410.0  ...  44.0   6900.0  5.0   no  yes   no   good  yes   no     0  \n",
      "8  138.0  ...  33.0   9600.0  4.0  yes  yes   no   good   no  yes     0  \n",
      "9   70.0  ...  29.0  12100.0  3.7  yes  yes   no   poor   no  yes     0  \n",
      "\n",
      "[10 rows x 25 columns]\n",
      "Index(['rbc', 'pc', 'pcc', 'ba', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane'], dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 25 columns):\n",
      "age      391 non-null float64\n",
      "bp       388 non-null float64\n",
      "sg       353 non-null float64\n",
      "al       354 non-null float64\n",
      "su       351 non-null float64\n",
      "rbc      248 non-null object\n",
      "pc       335 non-null object\n",
      "pcc      396 non-null object\n",
      "ba       396 non-null object\n",
      "bgr      356 non-null float64\n",
      "bu       381 non-null float64\n",
      "sc       383 non-null float64\n",
      "sod      313 non-null float64\n",
      "pot      312 non-null float64\n",
      "hemo     348 non-null float64\n",
      "pcv      329 non-null float64\n",
      "wc       294 non-null float64\n",
      "rc       269 non-null float64\n",
      "htn      398 non-null object\n",
      "dm       398 non-null object\n",
      "cad      398 non-null object\n",
      "appet    399 non-null object\n",
      "pe       399 non-null object\n",
      "ane      399 non-null object\n",
      "class    400 non-null int64\n",
      "dtypes: float64(14), int64(1), object(10)\n",
      "memory usage: 78.2+ KB\n",
      "    age     bp     sg   al   su       rbc        pc         pcc          ba  \\\n",
      "0  48.0   80.0  1.020  1.0  0.0       NaN    normal  notpresent  notpresent   \n",
      "1   7.0   50.0  1.020  4.0  0.0       NaN    normal  notpresent  notpresent   \n",
      "2  62.0   80.0  1.010  2.0  3.0    normal    normal  notpresent  notpresent   \n",
      "3  48.0   70.0  1.005  4.0  0.0    normal  abnormal     present  notpresent   \n",
      "4  51.0   80.0  1.010  2.0  0.0    normal    normal  notpresent  notpresent   \n",
      "5  60.0   90.0  1.015  3.0  0.0       NaN       NaN  notpresent  notpresent   \n",
      "6  68.0   70.0  1.010  0.0  0.0       NaN    normal  notpresent  notpresent   \n",
      "7  24.0   80.0  1.015  2.0  4.0    normal  abnormal  notpresent  notpresent   \n",
      "8  52.0  100.0  1.015  3.0  0.0    normal  abnormal     present  notpresent   \n",
      "9  53.0   90.0  1.020  2.0  0.0  abnormal  abnormal     present  notpresent   \n",
      "\n",
      "     bgr  ...  hemo   pcv       wc   rc  htn   dm  cad  appet   pe  ane  \n",
      "0  121.0  ...  15.4  44.0   7800.0  5.2  yes  yes   no   good   no   no  \n",
      "1  121.0  ...  11.3  38.0   6000.0  4.8   no   no   no   good   no   no  \n",
      "2  423.0  ...   9.6  31.0   7500.0  4.8   no  yes   no   poor   no  yes  \n",
      "3  117.0  ...  11.2  32.0   6700.0  3.9  yes   no   no   poor  yes  yes  \n",
      "4  106.0  ...  11.6  35.0   7300.0  4.6   no   no   no   good   no   no  \n",
      "5   74.0  ...  12.2  39.0   7800.0  4.4  yes  yes   no   good  yes   no  \n",
      "6  100.0  ...  12.4  36.0   8000.0  4.8   no   no   no   good   no   no  \n",
      "7  410.0  ...  12.4  44.0   6900.0  5.0   no  yes   no   good  yes   no  \n",
      "8  138.0  ...  10.8  33.0   9600.0  4.0  yes  yes   no   good   no  yes  \n",
      "9   70.0  ...   9.5  29.0  12100.0  3.7  yes  yes   no   poor   no  yes  \n",
      "\n",
      "[10 rows x 24 columns]\n",
      "    age     bp     sg   al   su       rbc        pc         pcc          ba  \\\n",
      "0  48.0   80.0  1.020  1.0  0.0    normal    normal  notpresent  notpresent   \n",
      "1   7.0   50.0  1.020  4.0  0.0    normal    normal  notpresent  notpresent   \n",
      "2  62.0   80.0  1.010  2.0  3.0    normal    normal  notpresent  notpresent   \n",
      "3  48.0   70.0  1.005  4.0  0.0    normal  abnormal     present  notpresent   \n",
      "4  51.0   80.0  1.010  2.0  0.0    normal    normal  notpresent  notpresent   \n",
      "5  60.0   90.0  1.015  3.0  0.0    normal    normal  notpresent  notpresent   \n",
      "6  68.0   70.0  1.010  0.0  0.0    normal    normal  notpresent  notpresent   \n",
      "7  24.0   80.0  1.015  2.0  4.0    normal  abnormal  notpresent  notpresent   \n",
      "8  52.0  100.0  1.015  3.0  0.0    normal  abnormal     present  notpresent   \n",
      "9  53.0   90.0  1.020  2.0  0.0  abnormal  abnormal     present  notpresent   \n",
      "\n",
      "     bgr  ...  hemo   pcv       wc   rc  htn   dm  cad  appet   pe  ane  \n",
      "0  121.0  ...  15.4  44.0   7800.0  5.2  yes  yes   no   good   no   no  \n",
      "1  121.0  ...  11.3  38.0   6000.0  4.8   no   no   no   good   no   no  \n",
      "2  423.0  ...   9.6  31.0   7500.0  4.8   no  yes   no   poor   no  yes  \n",
      "3  117.0  ...  11.2  32.0   6700.0  3.9  yes   no   no   poor  yes  yes  \n",
      "4  106.0  ...  11.6  35.0   7300.0  4.6   no   no   no   good   no   no  \n",
      "5   74.0  ...  12.2  39.0   7800.0  4.4  yes  yes   no   good  yes   no  \n",
      "6  100.0  ...  12.4  36.0   8000.0  4.8   no   no   no   good   no   no  \n",
      "7  410.0  ...  12.4  44.0   6900.0  5.0   no  yes   no   good  yes   no  \n",
      "8  138.0  ...  10.8  33.0   9600.0  4.0  yes  yes   no   good   no  yes  \n",
      "9   70.0  ...   9.5  29.0  12100.0  3.7  yes  yes   no   poor   no  yes  \n",
      "\n",
      "[10 rows x 24 columns]\n",
      "    age     bp     sg   al   su    bgr     bu    sc    sod  pot  ...  \\\n",
      "0  48.0   80.0  1.020  1.0  0.0  121.0   36.0   1.2  138.0  4.4  ...   \n",
      "1   7.0   50.0  1.020  4.0  0.0  121.0   18.0   0.8  138.0  4.4  ...   \n",
      "2  62.0   80.0  1.010  2.0  3.0  423.0   53.0   1.8  138.0  4.4  ...   \n",
      "3  48.0   70.0  1.005  4.0  0.0  117.0   56.0   3.8  111.0  2.5  ...   \n",
      "4  51.0   80.0  1.010  2.0  0.0  106.0   26.0   1.4  138.0  4.4  ...   \n",
      "5  60.0   90.0  1.015  3.0  0.0   74.0   25.0   1.1  142.0  3.2  ...   \n",
      "6  68.0   70.0  1.010  0.0  0.0  100.0   54.0  24.0  104.0  4.0  ...   \n",
      "7  24.0   80.0  1.015  2.0  4.0  410.0   31.0   1.1  138.0  4.4  ...   \n",
      "8  52.0  100.0  1.015  3.0  0.0  138.0   60.0   1.9  138.0  4.4  ...   \n",
      "9  53.0   90.0  1.020  2.0  0.0   70.0  107.0   7.2  114.0  3.7  ...   \n",
      "\n",
      "   pc_normal  pcc_present  ba_present  htn_yes  dm_no  dm_yes  cad_yes  \\\n",
      "0          1            0           0        1      0       1        0   \n",
      "1          1            0           0        0      1       0        0   \n",
      "2          1            0           0        0      0       1        0   \n",
      "3          0            1           0        1      1       0        0   \n",
      "4          1            0           0        0      1       0        0   \n",
      "5          1            0           0        1      0       1        0   \n",
      "6          1            0           0        0      1       0        0   \n",
      "7          0            0           0        0      0       1        0   \n",
      "8          0            1           0        1      0       1        0   \n",
      "9          0            1           0        1      0       1        0   \n",
      "\n",
      "   appet_poor  pe_yes  ane_yes  \n",
      "0           0       0        0  \n",
      "1           0       0        0  \n",
      "2           1       0        1  \n",
      "3           1       1        1  \n",
      "4           0       0        0  \n",
      "5           0       1        0  \n",
      "6           0       0        0  \n",
      "7           0       1        0  \n",
      "8           0       0        1  \n",
      "9           1       0        1  \n",
      "\n",
      "[10 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "#pd.set_option('display.max_rows', None) \n",
    "df.replace('?', np.nan, inplace=True)\n",
    "print(df.head(10))\n",
    "#df['dm'] = df['dm'].str.strip()\n",
    "df['class'] = df['class'].apply(lambda x: 1 if x =='ckd' else 0)\n",
    "#print(df.head(10))\n",
    "# numerical columns\n",
    "num_cols = ['age', 'bp', 'sg', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv', 'wc', 'rc']\n",
    "# categorical columns\n",
    "\n",
    "cate_cols = df.columns.drop('class').drop(num_cols)\n",
    "# display categorical columns\n",
    "print(cate_cols)\n",
    "# convert numerical data \n",
    "df[num_cols] = df[num_cols].apply(pd.to_numeric, errors='coerce')    \n",
    "df.info()    \n",
    "#print(df.head(10))\n",
    "\n",
    "# X and y\n",
    "X = df.drop(columns=['class'])\n",
    "Y = df['class']\n",
    "#print(X.head(10))\n",
    "#print(Y.head(10))\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy='median') #replace NaN with mean\n",
    "imputer = imputer.fit(X[num_cols]) # fit the imputer for first two features\n",
    "X[num_cols] = imputer.transform(X[num_cols]) # transform and store back\n",
    "print(X.head(10))\n",
    "\n",
    "# Imputing categorical data using the most frequent value\n",
    "imputercat = SimpleImputer(strategy=\"most_frequent\")  \n",
    "imputercat = imputercat.fit(X[cate_cols])\n",
    "X[cate_cols] = imputercat.transform(X[cate_cols])\n",
    "print(X.head(10))\n",
    "\n",
    "#perform dummy encoding\n",
    "X = pd.get_dummies(X, prefix_sep='_', drop_first=True)\n",
    "\n",
    "# X head\n",
    "print(X.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set/Test Set Split\n",
    " \n",
    "* Train the model on one set of data (the training set)\n",
    "* To test how well the model will generalize, we test it on a different set (the test set)\n",
    "* We do this to guard against overfitting the model\n",
    "    - The model relies to much on the features of the data in the training set.\n",
    "        - It may be an unusual sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train:       sepal_length  sepal_width  petal_length\n",
      "98            5.1          2.5           3.0\n",
      "126           6.2          2.8           4.8\n",
      "40            5.0          3.5           1.3\n",
      "133           6.3          2.8           5.1\n",
      "77            6.7          3.0           5.0\n",
      "\n",
      "y Train:  98     1\n",
      "126    2\n",
      "40     0\n",
      "133    2\n",
      "77     1\n",
      "Name: species, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Python Code\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = iris.iloc[:,0:3]\n",
    "y = iris.loc[:,'species']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1234)\n",
    "print(\"X Train: \",X_train.head())\n",
    "print(\"\\ny Train: \",y_train.head()) # species column is already encoded above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "\n",
    "* Many learning algorithms perform better if data is in range (0,1)\n",
    "* Some learning algorithms require normalized data\n",
    "    - Euclidean distance measures\n",
    "\n",
    "* Normalization (Min-max scaling)\n",
    "    -scale all features to (0,1)\n",
    "        \n",
    "$$ \\frac{x - min(x)}{max(x) - min(x)}$$\n",
    "        \n",
    "* Standardization\n",
    "    - Z-scores \n",
    "    - mean =  0, standard deviation = 1\n",
    "        \n",
    "$$\\frac{x - mean(x)}{standardDeviation(x)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train: \n",
      " [[-0.89800581 -1.23462679 -0.41454695]\n",
      " [ 0.45053534 -0.57321958  0.6087918 ]\n",
      " [-1.02060047  0.9700639  -1.38103354]\n",
      " [ 0.57312999 -0.57321958  0.77934826]\n",
      " [ 1.06350859 -0.13228144  0.72249611]\n",
      " [-1.26578977  0.74959484 -1.03992062]\n",
      " [-1.75616837 -0.35275051 -1.32418139]\n",
      " [-0.53022186  0.74959484 -1.15362493]\n",
      " [-1.51097907  1.19053297 -1.55159   ]\n",
      " [-1.02060047 -1.67556493 -0.24399049]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "print(\"X Train: \\n\",X_train[0:10,:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
