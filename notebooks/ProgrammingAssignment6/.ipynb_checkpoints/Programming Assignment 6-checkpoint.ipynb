{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment 6 - KNN\n",
    "\n",
    "You are to implement the KNN algorithm as discussed in the lecture notes for Breast Cancer Wisconsin (Diagnostic) Data Set and Predict whether the cancer is benign or malignant. Data set is provided to you with this assignment.\n",
    "\n",
    "You can read about this data set and/or download it from Kaggle at\n",
    "\n",
    "https://www.kaggle.com/uciml/breast-cancer-wisconsin-data#data.csv\n",
    "\n",
    "Yes, you need a Login, but you can log in with your Google ID.\n",
    "\n",
    "Read the Data Description given, and try to understand the data first. I will explain this on Tuesday 06/25/2019 during a Zoom session. I also included this data file with this assignment, but you still have to go to Kaggle and read the data description. \n",
    "\n",
    "The class distribution of cancer data is as follows: 357 benign, 212 malignant cases.\n",
    "\n",
    "Split the data set to 80-20 for training and testing data. You have to be careful here because the distribution of cases may not be uniform in the dataset. I suggest you randomize this process to get a more uniform distribution. Don't pick chunks here and there, just randomly pick records but make sure not to pick the same record twice. Explain how you accomplish this split. You can use any technique available, if you research a bit, you could find a ton of ways to do this. \n",
    "\n",
    "There are 32 columns in this dataset. Out of the 32, we can eliminate two columns (id and diagnosis). The diagnosis column is our dependent variable(Y-value)  You need to make decisions on how many columns (independent variables) you are going to use in your model. \n",
    "\n",
    "Be clear on your decisions and explain why you used them in a text box. If you use too many independent variables  (columns), your model could be overfitting, otherwise, it could be underfitting. I suggest that you START with 2-3 variables to find fewer correlations between these variables, then try different combinations of variables increasing the number. Lesser the correlation between independent variables, the higher the accuracy of your model.\n",
    "\n",
    "Show correlation matrices for the independent variables you are using. Once you are satisfied with your chosen variables, use them in your model.\n",
    "\n",
    "Show the descriptive statistics for the chosen training data, NOT the whole data set.\n",
    "\n",
    "Implement your KNN. This is where things get hairy! I want you to train your model with two different parameters, n_neighbors and Minkowski metric (where you change the p-value for Euclidean and Manhatten distances).\n",
    "\n",
    "Train your model using the following configurations, this will generate 6 different models. Do not change anything else!!\n",
    "\n",
    "    n_neighbors  minkowski metric(p)\n",
    "\n",
    "    3                p=1\n",
    "    4                p=1\n",
    "    5                p=1\n",
    "    ----------------------\n",
    "    3                p=2\n",
    "    4                p=2\n",
    "    5                p=2\n",
    "    \n",
    "Then predict the test set results and output your Confusion Matrix with error rate for each of the configured models. Then pick the model with the least error. You may have several models that have the same error rate, it doesn't matter, just pick one. \n",
    "\n",
    "Turn in all your findings, discussions, results, and code in a Jupyter Notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      True\n",
       "1      True\n",
       "2      True\n",
       "3      True\n",
       "4      True\n",
       "       ... \n",
       "564    True\n",
       "565    True\n",
       "566    True\n",
       "567    True\n",
       "568    True\n",
       "Name: radius_mean, Length: 569, dtype: bool"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData = pd.read_csv('datasets_180_408_data.csv')\n",
    "preData = rawData\n",
    "preData = preData.drop(\"id\",axis=1)\n",
    "\n",
    "incomplete = [\"radius_mean\",\"texture_mean\",\"perimeter_mean\",\"area_mean\",\"smoothness_mean\",\"compactness_mean\",\"concavity_mean\",\"concave points_mean\",\"symmetry_mean\",\"fractal_dimension_mean\",\"radius_se\",\"texture_se\",\"perimeter_se\",\"area_se\",\"smoothness_se\",\"compactness_se\",\"concavity_se\",\"concave points_se\",\"symmetry_se\",\"fractal_dimension_se\",\"radius_worst\",\"texture_worst\",\"perimeter_worst\",\"area_worst\",\"smoothness_worst\",\"compactness_worst\",\"concavity_worst\",\"concave points_worst\",\"symmetry_worst\",\"fractal_dimension_worst\"]\n",
    "for column in incomplete:\n",
    "    preData[column] = preData[column].fillna(preData[column].mean(skipna=True))\n",
    "preData\n",
    "\n",
    "X = preData.iloc[:, 2:-1]\n",
    "y = preData.iloc[:, 1].astype(dtype=bool)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=0, test_size=0.2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[114]]\n",
      "1.0\n",
      "[[114]]\n",
      "1.0\n",
      "[[114]]\n",
      "1.0\n",
      "[[114]]\n",
      "1.0\n",
      "[[114]]\n",
      "1.0\n",
      "[[114]]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=3,p=1,metric='euclidean')\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(cm)\n",
    "print(f1_score(y_test,y_pred))\n",
    "classifier = KNeighborsClassifier(n_neighbors=4,p=1,metric='euclidean')\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(cm)\n",
    "print(f1_score(y_test,y_pred))\n",
    "classifier = KNeighborsClassifier(n_neighbors=5,p=1,metric='euclidean')\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(cm)\n",
    "print(f1_score(y_test,y_pred))\n",
    "classifier = KNeighborsClassifier(n_neighbors=3,p=2,metric='euclidean')\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(cm)\n",
    "print(f1_score(y_test,y_pred))\n",
    "classifier = KNeighborsClassifier(n_neighbors=4,p=2,metric='euclidean')\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(cm)\n",
    "print(f1_score(y_test,y_pred))\n",
    "classifier = KNeighborsClassifier(n_neighbors=5,p=2,metric='euclidean')\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(cm)\n",
    "print(f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
